---
title: "Untitled"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r source}

source("./data/sequences.R")
source("../R/functions.R")

```

```{r libraries}

library(reshape2)
library(msa)
library(seqinr)
library(plotly)
library(stringr)
library(magrittr)
library(tidyverse)
library(ggplot2)
library(caret)
library(moments)

```


# R Markdown


```{r}

# Convert sequences to 3D chaos-game representation
# Drop irrelevant first coordinate, (0, 0, 0)

beta_cg <- lapply(beta_seq, function(x) seq_to_hypercomplex_cg4(x)[-1,])  
nadh_cg <- lapply(nadh, function(x) seq_to_hypercomplex_cg4(x)[-1,])  
sim_cg <- lapply(sim_fas, function(x) seq_to_hypercomplex_cg4(x)[-1,])  

```


```{r recognition}

# Calculate distances from landmarks (A, C, G, T, origin)
# A = c(0, (c(0, 0, 0) - (1/2)) * 2*sqrt(1/3))
# T = c(0, (c(1, 1, 0) - (1/2)) * 2*sqrt(1/3))
# C = c(0, (c(1, 0, 1) - (1/2)) * 2*sqrt(1/3))
# G = c(0, (c(0, 1, 1) - (1/2)) * 2*sqrt(1/3))
# Calculate the first 4 statistical moments for the distances

cg_descriptors <- function(cg_coords){
  A <- apply(cg_coords, 1, pt_dist, p2 = c(0, (c(0, 0, 0) - (1/2)) * 2*sqrt(1/3)) )
  T <- apply(cg_coords, 1, pt_dist, p2 = c(0, (c(1, 1, 0) - (1/2)) * 2*sqrt(1/3)) )
  C <- apply(cg_coords, 1, pt_dist, p2 = c(0, (c(1, 0, 1) - (1/2)) * 2*sqrt(1/3)) )
  G <- apply(cg_coords, 1, pt_dist, p2 = c(0, (c(0, 1, 1) - (1/2)) * 2*sqrt(1/3)) )
  o <- apply(cg_coords, 1, pt_dist, p2 = c(0, 0, 0, 0) )
  
  return(c(mean(A), var(A), skewness(A), #kurtosis(A),
           mean(T), var(T), skewness(T), #kurtosis(T),
           mean(C), var(C), skewness(C), #kurtosis(C),
           mean(G), var(G), skewness(G), #kurtosis(G),
           mean(o), var(o), skewness(o)#, kurtosis(o)
           ))
}

beta_desc <- t(sapply(beta_cg,  cg_descriptors)) 
beta_desc |> as.data.frame() |>
  preProcess(method = c("center", "scale")) |>
  predict(beta_desc |> as.data.frame() ) |> 
  dist() |>  hclust(method = "complete") |> 
  plot()

nadh_desc <- t(sapply(nadh_cg,  cg_descriptors)) 
nadh_desc |> as.data.frame() |>
  preProcess(method = c("center", "scale")) |>
  predict(nadh_desc |> as.data.frame() ) |> 
  dist() |>  hclust(method = "complete") |> 
  plot()

sim_desc <- t(sapply(sim_cg,  cg_descriptors)) 
sim_desc |> as.data.frame() |>
  preProcess(method = c("center", "scale")) |>
  predict(beta_desc |> as.data.frame() ) |> 
  dist() |>  hclust(method = "complete") |> 
  plot()

```

```{r entropy}

hist_nd <- function(df, breaks){
  col_indices <- 1:ncol(df)
  binned_df <- sapply(col_indices, function(x) (cut(df[,x], breaks[[x]], include.lowest = T)))
  colnames(binned_df) <- colnames(df)
  binned_df <- as.data.frame(binned_df)
  for(i in col_indices){
    binned_df[,i] <- factor(binned_df[,i], levels = levels(cut(df[,i], breaks[[i]], include.lowest = T)))
  } 
  return(table(binned_df) |> as.vector())
}



# The pattern with a lot of information is unlikely to occur 
# Informative = unlikely 

surprising_info <- function(prob){
  log(1/prob, base = 2)
}

entropy <- function(probabilities){ # Expected value of surprise / information
  sum(surprising_info(probabilities) * probabilities )
}

coordinate_entropy <- function(cgr_coords, bin_count){
  cgr_coords <- lapply(cgr_coords, 
                       function(x) preProcess(x, method = "zv") |>  predict(x))
  
  # Get histogram bounds
  hist_lb <- apply(do.call(rbind, cgr_coords), 2, min)
  hist_ub <- apply(do.call(rbind, cgr_coords), 2, max)
  
  # Get histogram intervals for each axis
  hist_breaks <- list()
  for(i in seq_along(hist_lb)){
    insert_me <- unique(seq(hist_lb[i], hist_ub[i], length.out = bin_count + 1))
    if(length(insert_me) < 2) insert_me <- c(insert_me, insert_me + 1) 
    hist_breaks[[i]] <- insert_me
  }
  # Get histogram bin counts
  tabulations <- lapply(cgr_coords, 
                        function(x) hist_df_unpaired(x, breaks = hist_breaks))
  tabulations <- sapply(tabulations, unlist)
  colnames(tabulations) <- names(cgr_coords)
  apply(tabulations, 1, function(x) entropy(sum(x)/length(x)))
  apply(tabulations, 1, function(x) entropy(table(x)[as.character(x)] / length(x)) )
  
  tabulations <- 
    apply(tabulations, 1, function(x) 
    (table(x)[as.character(x)] / length(x) * entropy(table(x)[as.character(x)] / length(x) )) ) |> t()
  colnames(tabulations) <- names(cgr_coords)
  
  return(t(tabulations))
}


  tabulations <- sapply(seq_along(dna_list), function(x) hist_nd(x.FUNC[[x]], breaks = hist_breaks))

  colnames(tabulations) <- names(dna_list)
  rownames(tabulations) <- 1:nrow(tabulations)
  
  tabulations <- tabulations[-which(rowSums(tabulations) == 0),]
  tabulations <- preProcess(t(tabulations), method = c("zv", preproc)) |> predict(t(tabulations)) |> t()
  rownames(tabulations) <- paste0("V", 1:nrow(tabulations))



coordinate_entropy(beta_cg, bin_count = 1000) |>
  dist() |> hclust(method = "complete") |>
  plot(axes = F, xlab = NULL, ylab = NULL, main = NULL, sub = NULL, ann = F)

coordinate_entropy(nadh_cg, bin_count = 1000) |>
  dist() |> hclust(method = "complete") |>
  plot(axes = F, xlab = NULL, ylab = NULL, main = NULL, sub = NULL, ann = F)

coordinate_entropy(sim_cg, bin_count = 1000) |>
  dist() |> hclust(method = "complete") |>
  plot(axes = F, xlab = NULL, ylab = NULL, main = NULL, sub = NULL, ann = F)




coordinate_signature(beta_cg, bin_count = 6110) |>  dist() |> hclust(method = "complete") |>
  plot(axes = F, xlab = NULL, ylab = NULL, main = NULL, sub = NULL, ann = F)


coordinate_signature(nadh_cg, bin_count = 6110) |>  dist() |> hclust(method = "complete") |>
  plot(axes = F, xlab = NULL, ylab = NULL, main = NULL, sub = NULL, ann = F)


coordinate_signature(sim_cg, bin_count = 6110) |>  dist() |> hclust(method = "complete") |>
  plot(axes = F, xlab = NULL, ylab = NULL, main = NULL, sub = NULL, ann = F)




```